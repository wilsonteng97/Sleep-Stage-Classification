{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyrem as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(32)\n",
    "b = np.ones(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12961047, 0.43948143, 0.33084862, 0.38431153, 0.67813697,\n",
       "       0.74755739, 0.51931955, 0.05536134, 0.97119633, 0.5035879 ,\n",
       "       0.16704713, 0.94710526, 0.2431946 , 0.68970834, 0.12166739,\n",
       "       0.04462404, 0.08808697, 0.4590722 , 0.5134365 , 0.17800184,\n",
       "       0.6206704 , 0.13942664, 0.30266957, 0.46036043, 0.63696304,\n",
       "       0.69136591, 0.13585384, 0.29425137, 0.6812238 , 0.4297085 ,\n",
       "       0.42880942, 0.79781275])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25825415594352313"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateStandardDeviation(a):\n",
    "    return np.std(a)\n",
    "calculateStandardDeviation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.random.normal(size=int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9991286420543838, 1.4141271837868732, 1.2250726442470694)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suppose EEG data mean very close to 0, from http://gilestrolab.github.io/pyrem/_modules/pyrem/univariate.html\n",
    "def calculateHjorth(a):\n",
    "    first_deriv = np.diff(a)\n",
    "    second_deriv = np.diff(a,2)\n",
    "    var_zero = np.mean(a ** 2)\n",
    "    var_d1 = np.mean(first_deriv ** 2)\n",
    "    var_d2 = np.mean(second_deriv ** 2)\n",
    "    activity = var_zero\n",
    "    morbidity = np.sqrt(var_d1 / var_zero)\n",
    "    complexity = np.sqrt(var_d2 / var_d1) / morbidity\n",
    "    return activity, morbidity, complexity\n",
    "calculateHjorth(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confused by term 'slide window' in the paper\n",
    "def calculateMMD(a):\n",
    "    return np.max(a) - np.min(a) # only one dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Petrosian Fractal Dimension, complexity\n",
    "def calculatePFD(a):\n",
    "    N = len(a)\n",
    "    diff = np.ediff1d(a)\n",
    "    sign_change = (diff[1:-1] * diff[0:-2] < 0)\n",
    "    M = sign_change.sum()\n",
    "    return np.log10(N) / (np.log10(N) + np.log10(N / (N + 0.4 * M)))\n",
    "calculatePFD(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.20795990200413\n",
      "403628.9763900714\n"
     ]
    }
   ],
   "source": [
    "#using Katz fractal dimension instead of Normalized Line Length (NLL)\n",
    "def calculateKFD(a):\n",
    "    distance = np.abs(np.ediff1d(a))\n",
    "    LL = distance.sum() #'line length'\n",
    "    LL_normalized = np.log10(np.divide(LL, distance.mean())) #original paper uses constant hyperparameter M=1\n",
    "    aux_d = a - a[0]\n",
    "    d = np.max(np.abs(aux_d[1:]))\n",
    "    return np.divide(LL_normalized, np.add(LL_normalized, np.log10(np.divide(d, LL))))\n",
    "\n",
    "print(calculateNLL(c))\n",
    "print(calculateNLL_(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hurst Exponent: failed to understand the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wzy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log Root Sum of Sequential Variations\n",
    "#measure the sequential variations\n",
    "def calculateLRSSV(a):\n",
    "    diff = np.ediff1d(a)\n",
    "    return np.log10(np.sqrt(np.sum(diff**2)))\n",
    "\n",
    "calculateLRSSV(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8196842663563354"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized Spectral Entropy, https://raphaelvallat.com/entropy/build/html/_modules/entropy/entropy.html\n",
    "from scipy.signal import periodogram\n",
    "def calculateSE(a):\n",
    "    _, psd = periodogram(a, 100)  #fft transform\n",
    "    psd_norm = np.divide(psd, psd.sum()) #power spectral density, measure of signal's power content versus frequency\n",
    "    se = -np.multiply(psd_norm, np.log2(psd_norm)).sum()\n",
    "    se /= np.log2(psd_norm.size)\n",
    "    return se\n",
    "calculateSE(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RÃ©nyi entropy (RE) a measure of the entropy of the distribution P = (p1, p2,..., pn)\n",
    "def calculateRE(a, m=2):\n",
    "    return 1/(1-m) * np.log2(np.sum(a**m))\n",
    "calculateRE(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037436658476834195\n",
      "0.020878997808118527\n",
      "0.05346290778783391\n",
      "0.055169901588860815\n",
      "0.01322894126230445\n",
      "0.05025536226430416\n",
      "0.0\n",
      "0.074249136844174\n",
      "0.0\n",
      "0.015731645229023927\n",
      "0.010954705297026246\n",
      "0.024091074154096948\n",
      "0.05947496446681155\n",
      "0.0016575692093764305\n",
      "0.017759241671262305\n",
      "0.0849864348951247\n",
      "0.04152350698679652\n",
      "0.0012882260257599532\n",
      "0.005883049300184351\n",
      "0.0\n",
      "0.0690379441417237\n",
      "0.027620497188938553\n",
      "0.08164195866019086\n",
      "0.0\n",
      "0.052745296659490126\n",
      "0.0\n",
      "0.03119328995360071\n",
      "0.09006015651350452\n",
      "0.010142105251218503\n",
      "0.0306519243265293\n",
      "0.03155100548333911\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.4647181237371938"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import digamma\n",
    "#Kraskov entropy (KE) an estimate for Shannon entropy using N samples of an m-dimensional random vector x\n",
    "#very confused???\n",
    "def calculateKE(a):\n",
    "    N = len(a)\n",
    "    k = 5 #what should be k?\n",
    "    sum_ = 0\n",
    "    for i in range(len(a)):\n",
    "        kth_nearest = sorted(sorted(a, key = lambda n: abs(a[i]-n))[:k])[-1]\n",
    "        ri = np.abs(kth_nearest - a[i])\n",
    "        if ri!=0:\n",
    "            sum_ += np.log(2*ri)\n",
    "    \n",
    "    \n",
    "    return digamma(N) - digamma(k) + 1/N * sum_\n",
    "calculateKE(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
